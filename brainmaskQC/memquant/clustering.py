from typing import List, Tuple

import ctypes
from multiprocessing import Process, Queue, Array

import numpy as np
from sklearn.base import BaseEstimator
from sklearn.metrics import rand_score


class RandClustering(object):
    def __init__(
        self, cluster_range: Tuple[int, int], clustering_method: BaseEstimator
    ) -> object:
        # range is inclusive
        self.cluster_range = cluster_range
        self.clustering_method = clustering_method

        self.clusterer = None
        self.n_clusters = None

    def predict(self, X: np.ndarray) -> np.ndarray:
        return self.clusterer.predict(X)

    def fit(
        self, X: np.ndarray, n_iterations: int = 500, n_workers: int = 12
    ) -> np.ndarray:
        # keep track of best score and labels
        best_avg_rand_score = None
        best_labels = None

        for n in range(self.cluster_range[0], self.cluster_range[1] + 1):
            # keep track of all clusterings
            clusterers = []
            # keep track of all labels generated by the n_iterations of clustering
            labels_all = []

            for i in range(n_iterations):
                # perform clustering
                clusterers.append(self.clustering_method(n))
                labels_all.append(clusterers[-1].fit_predict(X))

            # get labeling with the best average rand score for current n
            idx, avg_rand_score = self.__get_avg_rand_score(
                labels_all, n_workers=n_workers
            )

            print(f"{n} Clusters --- Avg Rand Score: {avg_rand_score}")

            labels = labels_all[idx]
            clusterer = clusterers[idx]

            # update attributes if new best avg_rand_score
            if best_avg_rand_score == None or avg_rand_score >= best_avg_rand_score:
                best_avg_rand_score = avg_rand_score
                self.clusterer = clusterer
                self.n_clusters = n
                best_labels = labels

        return best_labels

    @staticmethod
    def __get_avg_rand_score(
        Xs: List[np.ndarray], n_workers: int = 12
    ) -> Tuple[int, float]:
        # initialize shared array for keeping track of scores
        mp_arr = Array(ctypes.c_double, len(Xs) * (len(Xs) - 1))
        arr_shape = (len(Xs), len(Xs) - 1)

        # initialize queue
        queue_in = Queue()

        # initialize multiprocessing
        workers = [
            ClusterWorker(queue_in, mp_arr, arr_shape, Xs) for _ in range(n_workers)
        ]
        for worker in workers:
            worker.start()

        # push indices to the workers
        for i in range(len(Xs) - 1):
            for j in range(i + 1, len(Xs)):
                queue_in.put((i, j))

        # put termination flag into shared queue
        for _ in workers:
            queue_in.put(None)

        # join processes
        for worker in workers:
            worker.join()

        # convert to numpy array
        score_matrix = np.frombuffer(mp_arr.get_obj())
        score_matrix = np.reshape(score_matrix, arr_shape)

        # get average scores and index of best score
        avg_scores = np.mean(score_matrix, axis=1)
        index = np.argmax(avg_scores)

        return (index, avg_scores[index])


class ClusterWorker(Process):
    def __init__(
        self,
        queue_in: Queue,
        shared_arr: Array,
        arr_shape: Tuple[int],
        Xs: List[np.ndarray],
    ) -> object:
        Process.__init__(self, name="ClusterWorker")
        self.queue_in = queue_in
        self.Xs = Xs

        # convert shared array into numpy for further processing
        arr = np.frombuffer(shared_arr.get_obj())
        self.shared_arr = np.reshape(arr, arr_shape)

    def run(self):
        while True:
            idxs = self.queue_in.get()
            if idxs == None:
                # terminate
                break
            else:
                # get rand score and diagnonalize for efficient computation
                (i, j) = idxs
                score = rand_score(self.Xs[i], self.Xs[j])
                self.shared_arr[i, j - 1] = score
                self.shared_arr[j, i] = score


# class KMeansClustering(Clustering):

#     def __init__(self, n_clusters: Union[int, List[int]]) -> None:

#         super().__init__(n_clusters, lambda x: KMeans(x, n_init="auto"))


# class GMMClustering(Clustering):

#     def __init__(self, n_clusters: Union[int, List[int]]) -> None:

#         super().__init__(n_clusters, lambda x: GaussianMixture(x, n_init=10))
